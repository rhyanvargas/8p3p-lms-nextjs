# Learning Check - Phase 1 Testing Guide

## Setup Instructions

### 1. Environment Variables
Add to your `.env.local`:

```bash
# Required: Your Tavus API credentials
TAVUS_API_KEY=your_tavus_api_key_here
TAVUS_PERSONA_ID=your_persona_id_here

# Optional: Configuration
TAVUS_LEARNING_CHECK_DURATION=240
TAVUS_MAX_CONCURRENT_SESSIONS=10
```

**Get your credentials**:
1. Go to https://platform.tavus.io/api-keys
2. Create an API key
3. Go to https://platform.tavus.io/personas
4. Copy your "8p3p - AI Instructor Assistant" persona ID

### 2. Start Development Server
```bash
npm run dev
```

### 3. Open Browser Console
Press `F12` or `Cmd+Option+I` to open DevTools and view the Console tab.

---

## Test Scenarios

### Scenario 1: Locked State (Quiz Not Passed)
**Goal**: Verify Learning Check is locked when quiz not passed

**Steps**:
1. Navigate to a chapter with a quiz
2. Don't complete the quiz (or fail it)
3. Scroll to Learning Check section

**Expected**:
- âœ… Shows "Learning Check Locked" card
- âœ… Displays lock icon
- âœ… Shows message about needing to pass quiz
- âœ… Shows current quiz score if available

**Console Output**:
```
ðŸ“Š Analytics: lc_blocked_not_passed
{
  chapterId: "ch-1",
  userId: "user-123",
  quizScore: 60
}
```

---

### Scenario 2: Ready State (Quiz Passed)
**Goal**: Verify Learning Check is accessible after passing quiz

**Steps**:
1. Complete and pass the chapter quiz (â‰¥70%)
2. Scroll to Learning Check section

**Expected**:
- âœ… Shows "Learning Check â€” [Chapter Title]" card
- âœ… Displays "Start Learning Check" button
- âœ… Shows feature description and requirements
- âœ… Lists what to expect (4 minutes, questions, engagement threshold)

---

### Scenario 3: Start Conversation
**Goal**: Verify Tavus conversation creation and initialization

**Steps**:
1. From Ready state, click "Start Learning Check"
2. Allow camera and microphone permissions when prompted

**Expected**:
- âœ… Button shows "Starting..." loading state
- âœ… Conversation loads with AI avatar
- âœ… Timer starts counting down from 4:00
- âœ… Engagement progress bar appears (0s / 120s)
- âœ… Hair Check component appears (if Tavus configured)

**Console Output**:
```
ðŸ“Š Analytics: lc_started
{
  chapterId: "ch-1",
  userId: "user-123",
  timestamp: "2025-01-29T..."
}
```

---

### Scenario 4: Active Conversation
**Goal**: Verify engagement tracking and timer functionality

**Steps**:
1. Start a conversation
2. Speak with the AI avatar for 2+ minutes
3. Watch engagement progress bar

**Expected**:
- âœ… Timer counts down: 4:00 â†’ 3:59 â†’ ... â†’ 0:00
- âœ… Engagement time increments (mock: +1s every 2 seconds)
- âœ… Progress bar fills up toward 120s threshold
- âœ… Threshold indicator shows "âœ“" when â‰¥120s reached
- âœ… "End Session" button always available

**Console Monitoring**:
- Watch engagement time increment in component state
- No errors in console

---

### Scenario 5: Timer Expiration (Threshold Met)
**Goal**: Verify automatic termination at 4:00 with sufficient engagement

**Steps**:
1. Start conversation
2. Let timer run to 0:00 (or wait ~2 minutes for mock engagement to reach 120s)

**Expected**:
- âœ… Conversation automatically terminates
- âœ… Shows "Session Complete" card with green checkmark
- âœ… Displays engagement stats (e.g., "156s / 120s")
- âœ… Shows "Mark Learning Check Complete" button
- âœ… Progress bar shows completion

**Console Output**:
```
ðŸ“Š Analytics: lc_timeout
{
  chapterId: "ch-1",
  userId: "user-123",
  engagementTime: 156,
  thresholdMet: true
}

ðŸ’¾ Learning Check Data:
{
  chapterId: "ch-1",
  userId: "user-123",
  conversationId: "conv_abc123",
  startedAt: "2025-01-29T...",
  endedAt: "2025-01-29T...",
  duration: 240,
  engagementTime: 156,
  engagementPercent: 65,
  completed: false,
  transcript: "",
  endReason: "timeout",
  thresholdMet: true
}

âœ… Conversation terminated: conv_abc123
```

---

### Scenario 6: Timer Expiration (Threshold NOT Met)
**Goal**: Verify handling when engagement threshold not reached

**Steps**:
1. Start conversation
2. Immediately click "End Session" (before reaching 120s)

**Expected**:
- âœ… Shows "Engagement Threshold Not Met" card with warning icon
- âœ… Displays engagement stats (e.g., "45s / 120s")
- âœ… Shows error message explaining need for 120s
- âœ… Shows "Try Again" button
- âœ… No "Mark Complete" button

**Console Output**:
```
ðŸ“Š Analytics: lc_user_end
{
  chapterId: "ch-1",
  userId: "user-123",
  engagementTime: 45,
  thresholdMet: false
}

ðŸ’¾ Learning Check Data:
{
  ...
  engagementTime: 45,
  engagementPercent: 19,
  completed: false,
  endReason: "manual",
  thresholdMet: false
}
```

---

### Scenario 7: Manual End Session
**Goal**: Verify manual termination works correctly

**Steps**:
1. Start conversation
2. After 2+ minutes, click "End Session" button

**Expected**:
- âœ… Conversation terminates immediately
- âœ… Shows appropriate end state (complete/incomplete based on engagement)
- âœ… Logs termination analytics

**Console Output**:
```
ðŸ“Š Analytics: lc_terminated
{
  chapterId: "ch-1",
  conversationId: "conv_abc123",
  reason: "manual",
  engagementTime: 130
}

âœ… Conversation terminated: conv_abc123
```

---

### Scenario 8: Mark Complete
**Goal**: Verify completion flow

**Steps**:
1. Complete conversation with â‰¥120s engagement
2. Click "Mark Learning Check Complete"

**Expected**:
- âœ… Shows "Learning Check Completed" card with green checkmark
- âœ… Displays success message
- âœ… Calls `onComplete` callback (if provided)

**Console Output**:
```
ðŸ“Š Analytics: lc_completed
{
  chapterId: "ch-1",
  userId: "user-123",
  engagementTime: 156,
  engagementPercent: 65
}

ðŸ’¾ Learning Check Data:
{
  ...
  completed: true,
  endReason: "completed"
}
```

---

### Scenario 9: Page Navigation (Termination)
**Goal**: Verify conversation terminates when user navigates away

**Steps**:
1. Start conversation
2. Click browser back button or navigate to different page

**Expected**:
- âœ… Browser shows "Are you sure you want to leave?" confirmation
- âœ… If confirmed, conversation terminates via `sendBeacon`
- âœ… No errors in console

**Console Output**:
```
ðŸ“Š Analytics: lc_terminated
{
  chapterId: "ch-1",
  conversationId: "conv_abc123",
  reason: "component_unmount"
}
```

---

### Scenario 10: Tab Close (Termination)
**Goal**: Verify conversation terminates when tab/window closes

**Steps**:
1. Start conversation
2. Close browser tab

**Expected**:
- âœ… Browser shows "Are you sure?" confirmation
- âœ… Conversation terminates via `beforeunload` handler
- âœ… Uses `sendBeacon` for reliability

---

## Error Scenarios

### Error 1: Missing Environment Variables
**Steps**:
1. Remove `TAVUS_API_KEY` from `.env.local`
2. Try to start conversation

**Expected**:
- âœ… Shows error message: "Tavus configuration missing"
- âœ… Console error with details

### Error 2: Invalid API Key
**Steps**:
1. Set invalid `TAVUS_API_KEY`
2. Try to start conversation

**Expected**:
- âœ… Shows error message: "Failed to start session"
- âœ… Console error with Tavus API response

### Error 3: Network Failure
**Steps**:
1. Disable network in DevTools
2. Try to start conversation

**Expected**:
- âœ… Shows error message
- âœ… Graceful error handling (no crashes)

---

## Success Criteria

### Phase 1 MVP Complete When:
- âœ… All 10 test scenarios pass
- âœ… Console logging shows complete data capture
- âœ… No TypeScript errors
- âœ… No ESLint errors
- âœ… Conversation terminates reliably on all triggers
- âœ… Engagement tracking works (even if mocked)
- âœ… Timer enforces 4-minute hard stop
- âœ… Quiz-gating works correctly

---

## Next Steps (Phase 2)

After Phase 1 testing complete:
1. Set up ngrok for webhook testing
2. Configure perception queries in Tavus dashboard
3. Create perception webhook endpoint
4. Test perception analysis data capture
5. Verify enriched console logging with visual engagement

---

## Troubleshooting

### Issue: Conversation doesn't start
**Check**:
- Environment variables set correctly
- Tavus API key valid
- Persona ID exists in Tavus dashboard
- Network connectivity
- Browser console for errors

### Issue: Engagement not tracking
**Note**: Phase 1 uses mock engagement (increments every 2 seconds)
- This is expected behavior
- Phase 2 will use real Daily.co audio levels

### Issue: Timer doesn't stop at 0:00
**Check**:
- `onExpire` callback firing
- `handleTimerExpire` function called
- Console for termination logs

### Issue: Conversation doesn't terminate
**Check**:
- `/api/learning-checks/terminate` endpoint working
- Tavus API responding
- Console for termination errors
- Network tab in DevTools

---

## Demo Preparation

### Before Demo:
1. âœ… Test all scenarios
2. âœ… Clear browser console
3. âœ… Have valid Tavus credentials
4. âœ… Prepare chapter with passed quiz
5. âœ… Open DevTools console for data visibility

### During Demo:
1. Show locked state (quiz not passed)
2. Pass quiz
3. Show ready state
4. Start conversation
5. Show engagement tracking
6. Let timer run or manually end
7. Show completion data in console
8. Explain Phase 2 enhancements (perception, persistence)

---

**Questions?** See [Implementation Guide](./learning-check-implementation.md) for technical details.
